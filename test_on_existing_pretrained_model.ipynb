{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inference on Original Model"
      ],
      "metadata": {
        "id": "YvfXAYMp35Ok"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d25H8MNpvyso"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "HU1JZEwq59x4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive\n",
        "for sand storm images and checkpoints"
      ],
      "metadata": {
        "id": "EAesOg_x-XTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe4hvNE8wXJp",
        "outputId": "78a4eacf-25a0-428a-ae96-297b68d92e88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7TcPnnA1xoW",
        "outputId": "145c1ddf-c57f-44e9-c303-ba99ce6ce4f0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone Dehamer Git Repo and Import necessary files"
      ],
      "metadata": {
        "id": "cvaXRcrs-fQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Li-Chongyi/Dehamer.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAiEBI5e1kmA",
        "outputId": "cc36f6ab-f6fe-4122-cf58-4b35e9398bbc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Dehamer'...\n",
            "remote: Enumerating objects: 126, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 126 (delta 23), reused 3 (delta 2), pack-reused 67\u001b[K\n",
            "Receiving objects: 100% (126/126), 8.91 MiB | 16.44 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install packages\n",
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SS6hnRABUAa",
        "outputId": "53a9aebd-1715-4ad5-fa7a-f67aa6339b25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.9.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "%cd Dehamer/src\n",
        "from swin_unet import UNet_emb\n",
        "from utils import to_psnr, save_image\n",
        "%cd ../.."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7TolFqU-lvi",
        "outputId": "35c742b5-3aa3-4d36-c12d-7f1e445023b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Dehamer/src\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Testing"
      ],
      "metadata": {
        "id": "fZLZE0q431wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SIEDataset(Dataset):\n",
        "    \"\"\"Ensure there is only related files/directories in the specified SIE dataset directory\"\"\"\n",
        "    def __init__(self, dataset_dir):\n",
        "        super().__init__()\n",
        "\n",
        "        # get all image files in the directory\n",
        "\n",
        "        self.ground_truth_images_dir = os.path.join(dataset_dir, \"Ground_truth\")\n",
        "        self.sand_dust_images_dir = os.path.join(dataset_dir, \"Sand_dust_images\")\n",
        "\n",
        "        self.sand_dust_image_names = [file_name for file_name in os.listdir(self.sand_dust_images_dir) if os.path.isfile(os.path.join(self.sand_dust_images_dir, file_name)) and os.path.splitext(file_name)[1] == \".jpg\"]\n",
        "        self.ground_truth_image_names = [file_name for file_name in os.listdir(self.ground_truth_images_dir) if os.path.isfile(os.path.join(self.ground_truth_images_dir, file_name)) and os.path.splitext(file_name)[1] == \".jpg\"]\n",
        "\n",
        "        if len(self.sand_dust_image_names) != len(self.ground_truth_image_names):\n",
        "            raise ValueError(\"A number of sand-dust images and ground truth images must be the same\")\n",
        "\n",
        "\n",
        "        self.transform_input = Compose([ToTensor() , Normalize((0.64, 0.6, 0.58), (0.14,0.15, 0.152))])\n",
        "        self.transform_gt = Compose([ToTensor()])\n",
        "\n",
        "    def get_images(self, index):\n",
        "        img_file_name = self.sand_dust_image_names[index]\n",
        "\n",
        "        sand_dust_img = Image.open(os.path.join(self.sand_dust_images_dir, img_file_name))\n",
        "        ground_truth_img = Image.open(os.path.join(self.ground_truth_images_dir, img_file_name))\n",
        "\n",
        "        # ensure all images have the same size W_THRESHOLD and H_THRESHOLD\n",
        "        if self.is_image_smaller_than_threshold(sand_dust_img, W_THRESHOLD, H_THRESHOLD):\n",
        "            sand_dust_img = self.stretch_image(sand_dust_img, W_THRESHOLD, H_THRESHOLD)\n",
        "        sand_dust_img = self.crop_image(sand_dust_img, W_THRESHOLD, H_THRESHOLD)\n",
        "\n",
        "        if self.is_image_smaller_than_threshold(ground_truth_img, W_THRESHOLD, H_THRESHOLD):\n",
        "            ground_truth_img = self.stretch_image(ground_truth_img, W_THRESHOLD, H_THRESHOLD)\n",
        "        ground_truth_img = self.crop_image(ground_truth_img, W_THRESHOLD, H_THRESHOLD)\n",
        "\n",
        "\n",
        "        # NOTE: the model only accepts width & height that is multiple of 16\n",
        "        a = sand_dust_img.size\n",
        "        a_0 = a[1] - np.mod(a[1],16)\n",
        "        a_1 = a[0] - np.mod(a[0],16)\n",
        "        sand_dust_img = sand_dust_img.crop((0, 0, 0 + a_1, 0+a_0))\n",
        "        ground_truth_img = ground_truth_img.crop((0, 0, 0 + a_1, 0+a_0))\n",
        "\n",
        "        sand_dust_img = self.transform_input(sand_dust_img)\n",
        "        ground_truth_img = self.transform_gt(ground_truth_img)\n",
        "        return sand_dust_img, ground_truth_img, img_file_name\n",
        "\n",
        "    def crop_image(self, image, w_threshold, h_threshold):\n",
        "        assert image.width >= w_threshold and image.height >= h_threshold, \"to crop, image size must be bigger than or equal to the threshold values\"\n",
        "\n",
        "        # choose top and right randomly -> bottom and left automallycally determined\n",
        "        top = random.randint(0, image.height - h_threshold)  # inclusive\n",
        "        left = random.randint(0, image.width - w_threshold)\n",
        "\n",
        "        bottom = top + h_threshold\n",
        "        right = left + w_threshold\n",
        "\n",
        "        return image.crop((left, top, right, bottom))\n",
        "\n",
        "\n",
        "    def is_image_smaller_than_threshold(self, image, w_threshold, h_threshold) -> bool:\n",
        "        return image.width < w_threshold or image.height < h_threshold\n",
        "\n",
        "    def stretch_image(self, image, w_threshold, h_threshold):\n",
        "        aspect_ratio = h_threshold / w_threshold\n",
        "\n",
        "        if h_threshold - image.height < 0:\n",
        "            resize_based_on_width = True\n",
        "        elif w_threshold - image.width < 0:\n",
        "            resize_based_on_width = False\n",
        "        else:\n",
        "            # resize based on whichever the difference is smaller\n",
        "            resize_based_on_width = np.argmin([w_threshold - image.width, h_threshold - image.height])\n",
        "\n",
        "        if resize_based_on_width:\n",
        "            new_w = w_threshold\n",
        "            new_h = int(new_w * aspect_ratio)\n",
        "        else:\n",
        "            new_h = h_threshold\n",
        "            new_w = int(new_h / aspect_ratio)\n",
        "\n",
        "        return image.resize((new_w, new_h))\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        res = self.get_images(index)\n",
        "        return res\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sand_dust_image_names)"
      ],
      "metadata": {
        "id": "YsSgzkWjFQBm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(net, val_data_loader, device, category, save_tag=False):\n",
        "    psnr_list = []\n",
        "\n",
        "    for batch_id, val_data in enumerate(val_data_loader):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            haze, gt, image_name = val_data\n",
        "            haze = haze.to(device)\n",
        "            gt = gt.to(device)\n",
        "            dehaze = net(haze)\n",
        "\n",
        "        # --- Calculate the average PSNR --- #\n",
        "        psnr_list.extend(to_psnr(dehaze, gt))\n",
        "\n",
        "        # --- Save image --- #\n",
        "        if save_tag:\n",
        "            save_image(dehaze, image_name, category)\n",
        "\n",
        "    avr_psnr = sum(psnr_list) / len(psnr_list)\n",
        "    return avr_psnr"
      ],
      "metadata": {
        "id": "D-5t3WXdc6RJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# constants\n",
        "RUN_NAME = \"inference1\"\n",
        "CHECKPOINT_DIR = f\"/content/drive/MyDrive/FYP/Sem 2/4. Execution/checkpoints/original/dense/PSNR1662_SSIM05602.pt\"\n",
        "DATASET_DIR = \"/content/drive/MyDrive/FYP/Sem 2/4. Execution/Datasets/Sanddust Database/SIE_Dataset/Synthetic_images\"\n",
        "BATCH_SIZE = 16\n",
        "DATASET_NAME = \"SIE_Dataset\"\n",
        "\n",
        "W_THRESHOLD, H_THRESHOLD = 440, 330"
      ],
      "metadata": {
        "id": "RVrH6qpj9_Rd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "val_data_loader = DataLoader(SIEDataset(DATASET_DIR), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "net = UNet_emb()\n",
        "net = net.to(device)\n",
        "net.load_state_dict(torch.load(CHECKPOINT_DIR), strict=False)\n",
        "net.eval()\n",
        "\n",
        "val_psnr = test(net, val_data_loader, device, DATASET_NAME, save_tag=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKhLU1Kd2KnZ",
        "outputId": "b9ade8c5-7ba1-4b13-ecb3-11a983475b14"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/instancenorm.py:80: UserWarning: input's size at dim=1 does not match num_features. You can silence this warning by not passing in num_features, which is not used because affine=False\n",
            "  warnings.warn(f\"input's size at dim={feature_dim} does not match num_features. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xcyzeOZyzAMF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}